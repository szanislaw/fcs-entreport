{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b6e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import difflib\n",
    "import re\n",
    "import plotly.express as px\n",
    "import altair as alt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    /* Limit centered content to around 90% or a custom max width */\n",
    "    section[data-testid=\"stMain\"] > div[data-testid=\"stMainBlockContainer\"] {\n",
    "        max-width: 90rem;       /* adjust as desired (e.g., 80rem, 75rem, etc.) */\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "        padding-left: 2rem;\n",
    "        padding-right: 2rem;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    /* Expand the main container */\n",
    "    .main .block-container {\n",
    "        max-width: 100% !important;\n",
    "        padding-left: 2rem;\n",
    "        padding-right: 2rem;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# ─── Load model & tokenizer once ───\n",
    "@st.cache_resource\n",
    "def load_model_with_timing():\n",
    "    start_time = time.time()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"defog/sqlcoder-7b-2\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"defog/sqlcoder-7b-2\",\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    latency = end_time - start_time\n",
    "    return tokenizer, model, latency\n",
    "\n",
    "tokenizer, model, model_load_latency = load_model_with_timing()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Model loaded on {device}\")\n",
    "\n",
    "# ─── Initialize SQLite DB ───\n",
    "def initialize_database(conn, sql_file_path=\"schemas/cleaning.sql\"):\n",
    "    with open(sql_file_path, \"r\") as f:\n",
    "        sql_script = f.read()\n",
    "    conn.executescript(sql_script)\n",
    "    conn.commit()\n",
    "\n",
    "db_path = \"schemas/cleaning.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "required_tables = [\"regions\", \"hotels\", \"rooms\", \"guests\", \"bookings\", \"payments\", \"staff\",\n",
    "                   \"hotel_staff\", \"services\", \"room_services\", \"reviews\",\n",
    "                   \"shifts\", \"room_cleaning\", \"room_inspections\", \"lost_found\",\n",
    "                   \"guest_complaints\", \"training\", \"roster\"]\n",
    "\n",
    "existing_tables = set(row[0] for row in conn.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\").fetchall())\n",
    "\n",
    "if not any(tbl in existing_tables for tbl in required_tables):\n",
    "    initialize_database(conn, \"schemas/cleaning.sql\")\n",
    "\n",
    "# ─── PostgreSQL to SQLite cleaner ───\n",
    "def pg_to_sqlite(sql: str) -> str:\n",
    "    cleaned = sql\n",
    "    cleaned = re.sub(r'\\bpublic\\.', '', cleaned)\n",
    "    cleaned = re.sub(r'\\bTRUE\\b', '1', cleaned, flags=re.IGNORECASE)\n",
    "    cleaned = re.sub(r'\\bFALSE\\b', '0', cleaned, flags=re.IGNORECASE)\n",
    "    cleaned = re.sub(r'::\\s*\\w+', '', cleaned)\n",
    "    cleaned = re.sub(\n",
    "        r\"(?i)(\\b\\w+\\b\\.)?(\\b\\w+\\b)\\s+ILIKE\\s+'(.*?)'\",\n",
    "        lambda m: f\"LOWER({m.group(1) or ''}{m.group(2)}) LIKE '%{m.group(3).lower()}%'\",\n",
    "        cleaned\n",
    "    )\n",
    "    cleaned = re.sub(r'timestamp(?:\\(\\d+\\))?\\s+without time zone', 'datetime', cleaned, flags=re.IGNORECASE)\n",
    "    cleaned = re.sub(r'\\bSERIAL\\b', 'INTEGER', cleaned, flags=re.IGNORECASE)\n",
    "    cleaned = re.sub(r'USING\\s+btree', '', cleaned, flags=re.IGNORECASE)\n",
    "    cleaned = re.sub(\n",
    "        r'\\bAVG\\s*\\(\\s*([a-zA-Z_][\\w\\.]*)\\s*-\\s*([a-zA-Z_][\\w\\.]*)\\s*\\)',\n",
    "        r'ROUND(AVG((julianday(\\1) - julianday(\\2)) * 24 * 60), 2)',\n",
    "        cleaned\n",
    "    )\n",
    "    cleaned = re.sub(\n",
    "        r\"date_trunc\\(\\s*'month'\\s*,\\s*([a-zA-Z_][\\w\\.]*)\\)\",\n",
    "        r\"strftime('%Y-%m-01', \\1)\",\n",
    "        cleaned,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    cleaned = re.sub(r'\\bRETURNING\\b.*?(;|\\n|$)', '', cleaned, flags=re.IGNORECASE | re.DOTALL)\n",
    "    cleaned = cleaned.strip().rstrip(';')\n",
    "    return cleaned\n",
    "\n",
    "# ─── Generate schema dynamically ───\n",
    "def get_dynamic_schema_prompt(conn: sqlite3.Connection, question: str) -> str:\n",
    "    schema = []\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\")\n",
    "    tables = [row[0] for row in cursor.fetchall()]\n",
    "    for table in tables:\n",
    "        cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "        columns = cursor.fetchall()\n",
    "        col_defs = [f\"{col[1]} {col[2]}\" for col in columns] \n",
    "        schema.append(f\"CREATE TABLE {table} ({', '.join(col_defs)});\")\n",
    "    schema_text = \"\\n\".join(schema)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    \n",
    "### Task\n",
    "Generate a SQL query to answer the following question according to the provided schema below strictly:\n",
    "{question}\n",
    "\n",
    "### Database Schema\n",
    "{schema_text}\n",
    "\n",
    "Do not use any window functions. Use only the columns and tables provided in the schema. \n",
    "\n",
    "When generating the SQL query, ensure that:\n",
    "- The query is valid SQL syntax.\n",
    "- The query is optimized for SQLite.\n",
    "- The query does not contain any unnecessary complexity.\n",
    "\n",
    "If the verbose of the question is not clear, return an empty result set.\n",
    "\n",
    "If the question is not answerable with the provided schema, return an empty result set. \n",
    "If the question is not clear, return an empty result set. \n",
    "If the query is not a question, return an empty result set. \n",
    "If there are multiple tables, you may need to join them. \n",
    "If the question is about a specific table, use only that table.\n",
    "If the question is about a specific column, use only that column.\n",
    "If the question is about a specific value, use only that value.\n",
    "If the question is about a specific date, use only that date.\n",
    "If the question is about a specific time range, use only that time range.\n",
    "If the question is about a specific person, use only that person.\n",
    "If the question is about a specific location, use only that location.\n",
    "If the question is about a specific service, use only that service.\n",
    "\n",
    "### SQL\n",
    "\"\"\"\n",
    "    print(schema_text)  # Debugging: print the schema to console\n",
    "    print(prompt)  # Debugging: print the prompt to console\n",
    "    return prompt\n",
    "\n",
    "def clean_sql(raw_sql: str) -> str:\n",
    "    for kw in (\"SELECT\", \"WITH\", \"INSERT\", \"UPDATE\", \"DELETE\"):\n",
    "        idx = raw_sql.upper().find(kw)\n",
    "        if idx != -1:\n",
    "            return raw_sql[idx:].strip()\n",
    "    return raw_sql.strip()\n",
    "\n",
    "def postprocess_sql_for_dual_count(sql: str, question: str) -> str:\n",
    "    if (\n",
    "        \"COUNT\" in sql.upper()\n",
    "        and \"room_cleaning\" in sql\n",
    "        and \"room_inspections\" in sql\n",
    "        and \"passed\" in sql\n",
    "        and re.search(r'LOWER\\s*\\(\\s*s\\.staff_name\\s*\\)\\s+LIKE', sql, re.IGNORECASE)\n",
    "    ):\n",
    "        match_where = re.search(r'WHERE\\s+(.+)', sql, re.IGNORECASE)\n",
    "        if match_where:\n",
    "            where_clause = match_where.group(1)\n",
    "            new_sql = f\"\"\"\n",
    "                SELECT\n",
    "                    COUNT(DISTINCT rc.room_id) AS total_rooms_cleaned,\n",
    "                    COUNT(DISTINCT CASE WHEN ri.passed = 1 THEN rc.room_id END) AS rooms_passed_inspection\n",
    "                FROM room_cleaning rc\n",
    "                JOIN staff s ON rc.staff_id = s.staff_id\n",
    "                LEFT JOIN room_inspections ri ON rc.cleaning_id = ri.cleaning_id\n",
    "                WHERE {where_clause.replace('AND ri.passed = 1', '')}\n",
    "            \"\"\"\n",
    "            return new_sql.strip()\n",
    "    return sql\n",
    "\n",
    "def nl_to_sql(question: str) -> str:\n",
    "    prompt = get_dynamic_schema_prompt(conn, question)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id,                                  #can remove this line if pad_token_id is not needed\n",
    "    )\n",
    "    raw = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    sql = clean_sql(raw)\n",
    "    sql = postprocess_sql_for_dual_count(sql, question)\n",
    "    sqlite_sql = pg_to_sqlite(sql)\n",
    "    return sqlite_sql\n",
    "\n",
    "# ─── Logo and Title ───\n",
    "logo_path = \"assets/fcslogo.svg\"  # or .png if you prefer\n",
    "\n",
    "logo_col, title_col = st.columns([2, 10])\n",
    "with logo_col:\n",
    "    st.markdown(\"<div style='padding-top: 30px'></div>\", unsafe_allow_html=True)\n",
    "    st.image(logo_path, width=120)\n",
    "\n",
    "with title_col:\n",
    "    st.title(\"FCS Enterprise Report Demo\")\n",
    "    st.caption(f\"Model loaded in **{model_load_latency:.2f} seconds**\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .block-container {\n",
    "        padding-top: 2rem;\n",
    "    }\n",
    "    label[data-baseweb=\"input\"] > div {\n",
    "        font-size: 1.1rem;\n",
    "    }\n",
    "    .stTextInput > div > div > input {\n",
    "        font-size: 1.15rem !important;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# st.title(\":hotel: FCS Enterprise Report Demo\")\n",
    "# st.markdown(f\"<div style='font-size:1.2rem; color: #6c757d;'>Model loaded in <b>{model_load_latency:.2f} seconds</b></div>\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown(\"### :mag_right: What can I do for you today?\")\n",
    "user_query = st.text_input(\"\", placeholder=\"E.g. How many rooms have been cleaned?\")\n",
    "\n",
    "# ─── NL → SQL Mapping ───\n",
    "def query_mapping(user_input: str) -> str | None:\n",
    "    mappings = {\n",
    "        \"average number of rooms cleaned per shift\": \"\"\"\n",
    "            SELECT ROUND(AVG(rooms_cleaned), 2) AS avg_rooms_cleaned FROM shifts;\n",
    "        \"\"\",\n",
    "        \"average cleaning time per room\": \"\"\"\n",
    "            SELECT ROUND(AVG((julianday(cleaning_end) - julianday(cleaning_start)) * 24 * 60), 2) AS avg_cleaning_time_min FROM room_cleaning;\n",
    "        \"\"\",\n",
    "        \"room inspection pass rate\": \"\"\"\n",
    "            SELECT ROUND(SUM(CASE WHEN passed THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS pass_rate FROM room_inspections;\n",
    "        \"\"\",\n",
    "        \"how many rooms did donald anderson clean and pass the inspection\": \"\"\"\n",
    "            SELECT\n",
    "                COUNT(DISTINCT rc.room_id) AS total_rooms_cleaned,\n",
    "                COUNT(DISTINCT CASE WHEN ri.passed = 1 THEN rc.room_id END) AS rooms_passed_inspection\n",
    "            FROM room_cleaning rc\n",
    "            JOIN staff s ON rc.staff_id = s.staff_id\n",
    "            LEFT JOIN room_inspections ri ON rc.cleaning_id = ri.cleaning_id\n",
    "            WHERE LOWER(s.staff_name) LIKE '%donald anderson%'\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # Lowercase keys and input\n",
    "    user_input_clean = user_input.lower().strip()\n",
    "    phrases = list(mappings.keys())\n",
    "\n",
    "    # Fuzzy match threshold\n",
    "    best_match = difflib.get_close_matches(user_input_clean, phrases, n=1, cutoff=0.7)\n",
    "    if best_match:\n",
    "        return mappings[best_match[0]].strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "if user_query:\n",
    "    try:\n",
    "        sql = query_mapping(user_query)\n",
    "        if not sql:\n",
    "            sql = nl_to_sql(user_query)\n",
    "\n",
    "        if not sql.strip():\n",
    "            raise ValueError(\"The generated SQL query is empty.\")\n",
    "\n",
    "        try:\n",
    "            total_start_time = time.time()\n",
    "\n",
    "            # Time the SQL generation\n",
    "            sqlgen_start_time = time.time()\n",
    "            sql = query_mapping(user_query)\n",
    "            if not sql:\n",
    "                sql = nl_to_sql(user_query)\n",
    "            sqlgen_end_time = time.time()\n",
    "            sqlgen_latency = sqlgen_end_time - sqlgen_start_time\n",
    "\n",
    "            # Time the SQL execution\n",
    "            sqlexec_start_time = time.time()\n",
    "            df = pd.read_sql(sql, conn)\n",
    "            sqlexec_end_time = time.time()\n",
    "            sqlexec_latency = sqlexec_end_time - sqlexec_start_time\n",
    "\n",
    "            total_latency = sqlexec_end_time - total_start_time\n",
    "\n",
    "\n",
    "            st.success(\"Query successful.\")\n",
    "\n",
    "            # Begin result display\n",
    "            if not df.empty:\n",
    "                st.markdown(\"#### 📊 Result\")\n",
    "\n",
    "                # Check if it's a room cleaning + inspection summary\n",
    "                cols = df.columns.str.lower().tolist()\n",
    "                if set(['total_rooms_cleaned', 'rooms_passed_inspection']).issubset(cols):\n",
    "                    cleaned = df.iloc[0][cols.index('total_rooms_cleaned')]\n",
    "                    passed = df.iloc[0][cols.index('rooms_passed_inspection')]\n",
    "                    st.metric(label=\"🧹 Room Cleaning Summary\", value=f\"{int(cleaned)} rooms cleaned, {int(passed)} rooms passed\")\n",
    "                    \n",
    "                    \n",
    "                    ##not sure if this is needed, but keeping it for now\n",
    "                    if df.shape[0] <= 10 and df.shape[1] == 2 and df.dtypes[1] in ['int64', 'float64']:\n",
    "                        st.markdown(\"#### 📊 Bar Chart\")\n",
    "                        st.bar_chart(df.set_index(df.columns[0]))\n",
    "\n",
    "\n",
    "                elif df.shape[0] == 1 and all(dtype in ['int64', 'float64'] for dtype in df.dtypes):\n",
    "                    for col in df.columns:\n",
    "                        val = df[col].iloc[0]\n",
    "                        label = col.replace('_', ' ').title()\n",
    "\n",
    "                        # Format as percentage if column name suggests it's a rate\n",
    "                        if \"rate\" in col.lower() or \"percentage\" in col.lower():\n",
    "                            display_val = f\"{val * 100:.2f}%\" if isinstance(val, (float, int)) else val\n",
    "                        else:\n",
    "                            display_val = f\"{val:.2f}\" if isinstance(val, float) else val\n",
    "\n",
    "                        st.metric(label=label, value=display_val)\n",
    "\n",
    "                else:\n",
    "                    st.success(f\"✅ Returned {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "\n",
    "                    # Bar chart if suitable\n",
    "                    if df.shape[0] <= 10 and df.shape[1] == 2 and df.dtypes[1] in ['int64', 'float64']:\n",
    "                        st.markdown(\"#### 📊 Bar Chart\")\n",
    "                        st.bar_chart(df.set_index(df.columns[0]))\n",
    "\n",
    "                    # Summary statistics\n",
    "                    if any(dtype in ['int64', 'float64'] for dtype in df.dtypes):\n",
    "                        st.markdown(\"#### 📈 Summary Statistics\")\n",
    "                        st.dataframe(df.describe())\n",
    "\n",
    "                    # Expandable full table\n",
    "                    with st.expander(\"🔍 View Full Data Table\"):\n",
    "                        st.dataframe(df, use_container_width=True)\n",
    "\n",
    "                # CSV download\n",
    "                csv = df.to_csv(index=False).encode(\"utf-8\")\n",
    "                st.download_button(\"📥 Download Result as CSV\", data=csv, file_name=\"query_result.csv\", mime=\"text/csv\")\n",
    "\n",
    "                # 🔽 Moved to bottom\n",
    "                st.markdown(\"#### 🧠 Generated SQL Query\")\n",
    "                st.code(sql, language=\"sql\")\n",
    "\n",
    "            else:\n",
    "                st.warning(\"No results found.\")\n",
    "\n",
    "            # Show latency at bottom\n",
    "            st.markdown(f\"<div style='font-size:1.2rem; color: #6c757d;'>⏱️ Total time: <b>{total_latency:.4f} seconds</b> &nbsp; | &nbsp; 🧠 SQL generation: <b>{sqlgen_latency:.4f} sec</b> &nbsp; | &nbsp; 📦 SQL execution: <b>{sqlexec_latency:.4f} sec</b></div>\", unsafe_allow_html=True)\n",
    "\n",
    "        except Exception as sql_error:\n",
    "            st.error(\"❌ Something went wrong while executing your query.\")\n",
    "            with st.expander(\"Show full error\"):\n",
    "                st.code(str(sql_error), language=\"text\")\n",
    "\n",
    "    except Exception as gen_error:\n",
    "        st.error(f\"❌ Failed to generate a valid SQL query:\\n{gen_error}\")\n",
    "\n",
    "# ─── Housekeeping KPI Dashboard ──────────────────────────────────────────────\n",
    "\n",
    "# Optional CSS to help center the button more accurately\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    div[data-testid=\"column\"] div.stButton {\n",
    "        display: flex;\n",
    "        justify-content: center;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# ─── Initialize toggle state ───\n",
    "if \"show_kpis\" not in st.session_state:\n",
    "    st.session_state.show_kpis = False\n",
    "\n",
    "# ─── Centered Toggle Button ───\n",
    "col1, col2, col3 = st.columns(3)\n",
    "with col2:\n",
    "    st.markdown(\"<div style='height: 10px;'></div>\", unsafe_allow_html=True)\n",
    "    if st.button(\"📊 Show/Hide Housekeeping KPIs\", use_container_width=True):\n",
    "        st.session_state.show_kpis = not st.session_state.show_kpis\n",
    "        \n",
    "\n",
    "\n",
    "# ─── Conditional Display ───\n",
    "if st.session_state.show_kpis:\n",
    "    # Track KPI timing\n",
    "    kpi_total_start_time = time.time()\n",
    "    kpi_sqlgen_start_time = kpi_total_start_time\n",
    "    kpi_sqlgen_end_time = kpi_total_start_time  # assuming no SQL generation phase here\n",
    "\n",
    "    col1, col2 = st.columns([1, 1], gap=\"large\")  # Wider and spaced columns\n",
    "\n",
    "    with col1:\n",
    "        st.markdown(\"#### 👤 Top 5 Staff by Number of Assignments\")\n",
    "        query_staff = \"\"\"\n",
    "            SELECT assigned_name, COUNT(*) AS assignments\n",
    "            FROM hskp_cleaning_order\n",
    "            WHERE assigned_name IS NOT NULL AND TRIM(assigned_name) <> ''\n",
    "            GROUP BY assigned_name\n",
    "            ORDER BY assignments DESC\n",
    "            LIMIT 5;\n",
    "        \"\"\"\n",
    "        df_staff = pd.read_sql(query_staff, conn)\n",
    "\n",
    "        if not df_staff.empty and \"assigned_name\" in df_staff.columns:\n",
    "            fig = px.bar(\n",
    "                df_staff,\n",
    "                x=\"assigned_name\",\n",
    "                y=\"assignments\",\n",
    "                text=\"assignments\",\n",
    "                labels={\"assigned_name\": \"Staff Member\", \"assignments\": \"No. of Assignments\"},\n",
    "                title=\"Top 5 Staff by Cleaning Assignments\",\n",
    "            )\n",
    "            fig.update_traces(marker_color=\"#1f77b4\", textposition=\"outside\")\n",
    "            fig.update_layout(\n",
    "                xaxis_tickfont=dict(size=14),\n",
    "                yaxis_title=\"Number of Assignments\",\n",
    "                xaxis_title=\"Staff Name\",\n",
    "                title_font_size=18,\n",
    "                height=450,\n",
    "                margin=dict(l=30, r=30, t=50, b=100),\n",
    "            )\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"No staff assignment data available.\")\n",
    "\n",
    "    with col2:\n",
    "        st.markdown(\"#### 🧼 Top 5 Cleaning Services by Type\")\n",
    "        query_service_type = \"\"\"\n",
    "            SELECT service_type, COUNT(*) AS total\n",
    "            FROM hskp_cleaning_order\n",
    "            WHERE service_type IS NOT NULL AND TRIM(service_type) <> ''\n",
    "            GROUP BY service_type\n",
    "            ORDER BY total DESC\n",
    "            LIMIT 5;\n",
    "        \"\"\"\n",
    "        df_service_type = pd.read_sql(query_service_type, conn)\n",
    "\n",
    "        if not df_service_type.empty:\n",
    "            chart_services = alt.Chart(df_service_type).mark_bar(cornerRadiusTopLeft=5, cornerRadiusTopRight=5).encode(\n",
    "                x=alt.X(\"service_type:N\", sort='-y', title=\"Service Type\"),\n",
    "                y=alt.Y(\"total:Q\", title=\"Number of Tasks\"),\n",
    "                color=alt.value(\"#4e79a7\"),\n",
    "                tooltip=[\"service_type\", \"total\"]\n",
    "            ).properties(\n",
    "                height=350,\n",
    "                title=\"Top 5 Cleaning Services by Type\"\n",
    "            )\n",
    "            st.altair_chart(chart_services, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"No service type data available.\")\n",
    "    \n",
    "\n",
    "    # ─── Row 2: Full-width Time vs Credit ───\n",
    "    st.markdown(\"#### ⏱️ Average Time to Completion vs. Credit\")\n",
    "    query_time_vs_credit = \"\"\"\n",
    "        SELECT credit, AVG(time_spent) AS avg_time_spent\n",
    "        FROM hskp_cleaning_order\n",
    "        WHERE credit IS NOT NULL AND time_spent IS NOT NULL\n",
    "        GROUP BY credit\n",
    "        ORDER BY credit ASC;\n",
    "    \"\"\"\n",
    "    df_time_vs_credit = pd.read_sql(query_time_vs_credit, conn)\n",
    "\n",
    "    if not df_time_vs_credit.empty:\n",
    "        chart_time_credit = alt.Chart(df_time_vs_credit).mark_line(point=True).encode(\n",
    "            x=alt.X(\"credit:Q\", title=\"Credit\"),\n",
    "            y=alt.Y(\"avg_time_spent:Q\", title=\"Avg. Time Spent (mins)\"),\n",
    "            tooltip=[\"credit\", \"avg_time_spent\"]\n",
    "        ).properties(\n",
    "            height=350,\n",
    "            title=\"Average Time to Completion vs. Credit\"\n",
    "        )\n",
    "        st.altair_chart(chart_time_credit, use_container_width=True)\n",
    "    else:\n",
    "        st.warning(\"No time vs credit data available.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # KPI: Daily Cleaning Volume (Past 7 Days) - demonstration of failback handling\n",
    "    st.markdown(\"#### 🧹 Daily Cleaning Volume (Past 7 Days)\")\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT DATE(created_date) AS day, COUNT(*) AS total\n",
    "        FROM hskp_cleaning_order\n",
    "        WHERE created_date IS NOT NULL AND TRIM(created_date) <> ''\n",
    "        AND DATE(created_date) >= DATE('now', '-7 days')\n",
    "        GROUP BY day\n",
    "        ORDER BY day;\n",
    "    \"\"\"\n",
    "\n",
    "    df_daily = pd.read_sql(query, conn)\n",
    "\n",
    "    if not df_daily.empty and \"day\" in df_daily.columns:\n",
    "        df_daily[\"day\"] = pd.to_datetime(df_daily[\"day\"], errors='coerce')\n",
    "        df_daily = df_daily.dropna(subset=[\"day\"])\n",
    "        df_daily.set_index(\"day\", inplace=True)\n",
    "        st.line_chart(df_daily[\"total\"])\n",
    "    else:\n",
    "        st.warning(\"No daily cleaning data available for the past 7 days.\")\n",
    "\n",
    "    \n",
    "    st.markdown(\"## 🧠 Top 10 Strategic Housekeeping KPIs\")\n",
    "\n",
    "    kpi_queries = {\n",
    "        \"🧼 Cleaning Order Completion Rate (%)\": \"\"\"\n",
    "            SELECT ROUND(\n",
    "                SUM(CASE WHEN job_stop IS NOT NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2\n",
    "            ) AS completion_rate\n",
    "            FROM hskp_cleaning_order;\n",
    "        \"\"\",\n",
    "\n",
    "        \"🧑‍💼 Avg. Cleanings per Attendant per Day\": \"\"\"\n",
    "            SELECT ROUND(AVG(cnt), 2) FROM (\n",
    "                SELECT COUNT(*) AS cnt\n",
    "                FROM hskp_cleaning_order_detail\n",
    "                GROUP BY user_uuid, DATE(created_date)\n",
    "            );\n",
    "        \"\"\",\n",
    "\n",
    "        \"📉 % of Cleanings Cancelled\": \"\"\"\n",
    "            SELECT ROUND(\n",
    "                SUM(CASE WHEN cancelled_date IS NOT NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2\n",
    "            ) AS cancellation_rate\n",
    "            FROM hskp_cleaning_order;\n",
    "        \"\"\",\n",
    "\n",
    "        \"👤 Most Frequently Assigned Staff\": \"\"\"\n",
    "            SELECT assigned_name, COUNT(*) AS assignments\n",
    "            FROM hskp_cleaning_order\n",
    "            WHERE assigned_name IS NOT NULL\n",
    "            GROUP BY assigned_name\n",
    "            ORDER BY assignments DESC\n",
    "            LIMIT 1;\n",
    "        \"\"\",\n",
    "\n",
    "        \"🚩 % of Tasks with Special Remarks\": \"\"\"\n",
    "            SELECT ROUND(\n",
    "                SUM(CASE WHEN remarks IS NOT NULL AND TRIM(remarks) <> '' THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2\n",
    "            ) AS flagged_percentage\n",
    "            FROM hskp_cleaning_order;\n",
    "        \"\"\",\n",
    "\n",
    "        \"🏷️ Most Common Additional Task Type\": \"\"\"\n",
    "            SELECT additional_task_id, COUNT(*) AS freq\n",
    "            FROM hskp_cleaning_order_map_additional_task\n",
    "            GROUP BY additional_task_id\n",
    "            ORDER BY freq DESC\n",
    "            LIMIT 1;\n",
    "        \"\"\",\n",
    "\n",
    "        \"📋 Avg. Checklist Score (Where Available)\": \"\"\"\n",
    "            SELECT ROUND(AVG(score), 2) AS avg_score\n",
    "            FROM hskp_cleaning_order_map_checklist\n",
    "            WHERE score IS NOT NULL;\n",
    "        \"\"\",\n",
    "\n",
    "        \"📉 Inspection Failure Rate (%)\": \"\"\"\n",
    "            SELECT ROUND(\n",
    "                SUM(CASE WHEN inspection_result = 0 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2\n",
    "            ) AS failure_rate\n",
    "            FROM hskp_cleaning_order_inspection;\n",
    "        \"\"\",\n",
    "\n",
    "        \"🔁 Repeat Cleanings on Same Room in 24hrs\": \"\"\"\n",
    "            SELECT COUNT(*) FROM (\n",
    "                SELECT location_uuid, DATE(created_date) AS day, COUNT(*) AS cnt\n",
    "                FROM hskp_cleaning_order\n",
    "                GROUP BY location_uuid, day\n",
    "                HAVING cnt > 1\n",
    "            );\n",
    "        \"\"\",\n",
    "\n",
    "        \"🕓 % of Cleanings Exceeding Allocated Time\": \"\"\"\n",
    "            SELECT ROUND(\n",
    "                SUM(CASE\n",
    "                    WHEN job_stop IS NOT NULL AND duration IS NOT NULL AND\n",
    "                         (julianday(job_stop) - julianday(job_start)) * 24 * 60 > duration\n",
    "                    THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2\n",
    "            ) AS overrun_rate\n",
    "            FROM hskp_cleaning_order\n",
    "            WHERE job_start IS NOT NULL AND job_stop IS NOT NULL;\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    for idx, (title, query) in enumerate(kpi_queries.items()):\n",
    "        with (col1 if idx % 2 == 0 else col2):\n",
    "            st.markdown(f\"### {title}\")\n",
    "            try:\n",
    "                start = time.time()\n",
    "                df_kpi = pd.read_sql(query, conn)\n",
    "                end = time.time()\n",
    "                if not df_kpi.empty:\n",
    "                    value = df_kpi.iloc[0, 0]\n",
    "                    formatted_value = f\"{value:.2f}\" if isinstance(value, (float, int)) else str(value)\n",
    "                    st.metric(label=title, value=formatted_value)\n",
    "                    st.caption(f\"⏱️ Loaded in {end - start:.4f} sec\")\n",
    "                else:\n",
    "                    st.warning(\"No data available.\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error loading KPI: {e}\")\n",
    "                \n",
    "\n",
    "    kpi_total_end_time = time.time()\n",
    "    kpi_sqlexec_latency = kpi_total_end_time - kpi_sqlgen_end_time\n",
    "    kpi_total_latency = kpi_total_end_time - kpi_total_start_time\n",
    "\n",
    "    st.markdown(\n",
    "        f\"<div style='font-size:1.1rem; color: #6c757d;'>⏱️ Total time: <b>{kpi_total_latency:.4f} seconds</b> &nbsp; | &nbsp; 🧠 SQL generation: <b>{0.0000:.4f} sec</b> &nbsp; | &nbsp; 📦 SQL execution: <b>{kpi_sqlexec_latency:.4f} sec</b></div>\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "                    \n",
    "\n",
    "    # KPI: Top 5 Staff by Number of Assignments\n",
    "    # st.markdown(\"#### 👤 Top 5 Staff by Number of Assignments\")\n",
    "\n",
    "    # query_staff = \"\"\"\n",
    "    #     SELECT assigned_name, COUNT(*) AS assignments\n",
    "    #     FROM hskp_cleaning_order\n",
    "    #     WHERE assigned_name IS NOT NULL AND TRIM(assigned_name) <> ''\n",
    "    #     GROUP BY assigned_name\n",
    "    #     ORDER BY assignments DESC\n",
    "    #     LIMIT 5;\n",
    "    # \"\"\"\n",
    "\n",
    "    # df_staff = pd.read_sql(query_staff, conn)\n",
    "\n",
    "    # if not df_staff.empty and \"assigned_name\" in df_staff.columns:\n",
    "    #     df_staff.set_index(\"assigned_name\", inplace=True)\n",
    "    #     st.bar_chart(df_staff, use_container_width=True)\n",
    "    # else:\n",
    "    #     st.warning(\"No staff assignment data available.\")\n",
    "    \n",
    "    \n",
    "    # st.markdown(\"#### 👤 Top 5 Staff by Number of Assignments\")\n",
    "\n",
    "    # query_staff = \"\"\"\n",
    "    #     SELECT assigned_name, COUNT(*) AS assignments\n",
    "    #     FROM hskp_cleaning_order\n",
    "    #     WHERE assigned_name IS NOT NULL AND TRIM(assigned_name) <> ''\n",
    "    #     GROUP BY assigned_name\n",
    "    #     ORDER BY assignments DESC\n",
    "    #     LIMIT 5;\n",
    "    # \"\"\"\n",
    "\n",
    "    # df_staff = pd.read_sql(query_staff, conn)\n",
    "\n",
    "    # if not df_staff.empty and \"assigned_name\" in df_staff.columns:\n",
    "    #     fig = px.bar(\n",
    "    #         df_staff,\n",
    "    #         x=\"assigned_name\",\n",
    "    #         y=\"assignments\",\n",
    "    #         text=\"assignments\",\n",
    "    #         labels={\"assigned_name\": \"Staff Member\", \"assignments\": \"No. of Assignments\"},\n",
    "    #         title=\"Top 5 Staff by Cleaning Assignments\",\n",
    "    #     )\n",
    "    #     fig.update_traces(marker_color=\"#1f77b4\", textposition=\"outside\")\n",
    "    #     fig.update_layout(\n",
    "    #         xaxis_tickfont=dict(size=14),\n",
    "    #         yaxis_title=\"Number of Assignments\",\n",
    "    #         xaxis_title=\"Staff Name\",\n",
    "    #         title_font_size=20,\n",
    "    #         margin=dict(l=40, r=40, t=60, b=120),\n",
    "    #         height=450\n",
    "    #     )\n",
    "    #     st.plotly_chart(fig, use_container_width=True)\n",
    "    # else:\n",
    "    #     st.warning(\"No staff assignment data available.\")\n",
    "        \n",
    "    # st.markdown(\"#### 🧼 Top 5 Cleaning Services by Type\")\n",
    "\n",
    "    # query_service_type = \"\"\"\n",
    "    #     SELECT service_type, COUNT(*) AS total\n",
    "    #     FROM hskp_cleaning_order\n",
    "    #     WHERE service_type IS NOT NULL AND TRIM(service_type) <> ''\n",
    "    #     GROUP BY service_type\n",
    "    #     ORDER BY total DESC\n",
    "    #     LIMIT 5;\n",
    "    # \"\"\"\n",
    "    # df_service_type = pd.read_sql(query_service_type, conn)\n",
    "\n",
    "    # if not df_service_type.empty:\n",
    "    #     chart_services = alt.Chart(df_service_type).mark_bar(cornerRadiusTopLeft=5, cornerRadiusTopRight=5).encode(\n",
    "    #         x=alt.X(\"service_type:N\", sort='-y', title=\"Service Type\"),\n",
    "    #         y=alt.Y(\"total:Q\", title=\"Number of Tasks\"),\n",
    "    #         color=alt.value(\"#4e79a7\"),\n",
    "    #         tooltip=[\"service_type\", \"total\"]\n",
    "    #     ).properties(\n",
    "    #         width=600,\n",
    "    #         height=350,\n",
    "    #         title=\"Top 5 Cleaning Services by Type\"\n",
    "    #     )\n",
    "    #     st.altair_chart(chart_services, use_container_width=True)\n",
    "    # else:\n",
    "    #     st.warning(\"No service type data available.\")\n",
    "\n",
    "    # st.markdown(\"#### ⏱️ Average Time to Completion vs. Credit\")\n",
    "\n",
    "    # query_time_vs_credit = \"\"\"\n",
    "    #     SELECT credit, AVG(time_spent) AS avg_time_spent\n",
    "    #     FROM hskp_cleaning_order\n",
    "    #     WHERE credit IS NOT NULL AND time_spent IS NOT NULL\n",
    "    #     GROUP BY credit\n",
    "    #     ORDER BY credit ASC;\n",
    "    # \"\"\"\n",
    "    # df_time_vs_credit = pd.read_sql(query_time_vs_credit, conn)\n",
    "\n",
    "    # if not df_time_vs_credit.empty:\n",
    "    #     chart_time_credit = alt.Chart(df_time_vs_credit).mark_line(point=True).encode(\n",
    "    #         x=alt.X(\"credit:Q\", title=\"Credit\"),\n",
    "    #         y=alt.Y(\"avg_time_spent:Q\", title=\"Avg. Time Spent (mins)\"),\n",
    "    #         tooltip=[\"credit\", \"avg_time_spent\"]\n",
    "    #     ).properties(\n",
    "    #         width=600,\n",
    "    #         height=350,\n",
    "    #         title=\"Average Time to Completion vs. Credit\"\n",
    "    #     )\n",
    "    #     st.altair_chart(chart_time_credit, use_container_width=True)\n",
    "    # else:\n",
    "    #     st.warning(\"No time vs credit data available.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
